{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 81)\n",
      "(1459, 80)\n",
      "   Id  MSSubClass MSZoning  LotFrontage SaleType SaleCondition  SalePrice\n",
      "0   1          60       RL         65.0       WD        Normal     208500\n",
      "1   2          20       RL         80.0       WD        Normal     181500\n",
      "2   3          60       RL         68.0       WD        Normal     223500\n",
      "3   4          70       RL         60.0       WD       Abnorml     140000\n",
      "     Id  MSSubClass MSZoning  LotFrontage  YrSold SaleType SaleCondition\n",
      "0  1461          20       RH         80.0    2010       WD        Normal\n",
      "1  1462          20       RL         81.0    2010       WD        Normal\n",
      "2  1463          60       RL         74.0    2010       WD        Normal\n",
      "3  1464          60       RL         78.0    2010       WD        Normal\n"
     ]
    }
   ],
   "source": [
    "data_root = \"D:\\Downloads\\Data\\Kaggle\\house-prices-advanced-regression-techniques\"\n",
    "\n",
    "train_data = pd.read_csv(os.path.join(data_root, 'train.csv'))\n",
    "test_data = pd.read_csv(os.path.join(data_root, 'test.csv'))\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(train_data.iloc[0:4, [0, 1, 2, 3, -3, -2, -1]])\n",
    "print(test_data.iloc[0:4, [0, 1, 2, 3, -3, -2, -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MSSubClass  LotFrontage   LotArea  OverallQual  SaleCondition_Normal  \\\n",
      "0    0.067320    -0.184443 -0.217841     0.646073                     1   \n",
      "1   -0.873466     0.458096 -0.072032    -0.063174                     1   \n",
      "2    0.067320    -0.055935  0.137173     0.646073                     1   \n",
      "3    0.302516    -0.398622 -0.078371     0.646073                     0   \n",
      "\n",
      "   SaleCondition_Partial  SaleCondition_nan  \n",
      "0                      0                  0  \n",
      "1                      0                  0  \n",
      "2                      0                  0  \n",
      "3                      0                  0  \n"
     ]
    }
   ],
   "source": [
    "all_features = pd.concat((train_data.iloc[:, 1:-1], test_data.iloc[:, 1:]))\n",
    "\n",
    "numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index\n",
    "all_features[numeric_features] = all_features[numeric_features].apply(\n",
    "    lambda x: (x - x.mean()) / (x.std()))\n",
    "all_features[numeric_features] = all_features[numeric_features].fillna(0)\n",
    "\n",
    "all_features = pd.get_dummies(all_features, dummy_na=True)\n",
    "all_features *= 1\n",
    "print(all_features.iloc[0:4, [0, 1, 2, 3, -3, -2, -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = train_data.shape[0]\n",
    "train_features = torch.tensor(all_features[:n_train].values, dtype=torch.float32)\n",
    "test_features = torch.tensor(all_features[n_train:].values, dtype=torch.float32)\n",
    "train_labels = torch.tensor(train_data.SalePrice.values.reshape(-1, 1), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()\n",
    "hidden_layer = 10\n",
    "in_features = train_features.shape[1]\n",
    "\n",
    "def get_net():\n",
    "    net = nn.Sequential(nn.Linear(in_features, hidden_layer),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(hidden_layer, 1))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_rmse(net, features, labels):\n",
    "    clipped_preds = torch.clamp(net(features), 1, float('inf'))\n",
    "    rmse = torch.sqrt(loss(torch.log(clipped_preds),\n",
    "                           torch.log(labels)))\n",
    "    return rmse.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_array(data_arrays, batch_size, is_train=True):\n",
    "    \"\"\"Construct a PyTorch data iterator.\n",
    "    Defined in :numref:`sec_utils`\"\"\"\n",
    "    dataset = torch.utils.data.TensorDataset(*data_arrays)\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "def train(net, train_features, train_labels, test_features, test_labels,\n",
    "          num_epochs, learning_rate, weight_decay, batch_size):\n",
    "    train_ls, test_ls = [], []\n",
    "    train_iter = load_array((train_features, train_labels), batch_size)\n",
    "    optimizer = torch.optim.Adam(net.parameters(),\n",
    "                                 lr = learning_rate,\n",
    "                                 weight_decay = weight_decay)\n",
    "    for epoch in range(num_epochs):\n",
    "        for X, y in train_iter:\n",
    "            optimizer.zero_grad()\n",
    "            l = loss(net(X), y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "        train_ls.append(log_rmse(net, train_features, train_labels))\n",
    "        if (epoch + 1) % int(math.sqrt(num_epochs)) == 0:\n",
    "            print(f\"[{epoch}] log rmse:{train_ls[-1]:.5f}\")\n",
    "        if test_labels is not None:\n",
    "            test_ls.append(log_rmse(net, test_features, test_labels))\n",
    "    return train_ls, test_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_fold_data(k, i, X, y):\n",
    "    assert k > 1\n",
    "    fold_size = X.shape[0] // k\n",
    "    X_train, y_train = None, None\n",
    "    for j in range(k):\n",
    "        idx = slice(j * fold_size, (j + 1) * fold_size)\n",
    "        X_part, y_part = X[idx, :], y[idx]\n",
    "        if j == i:\n",
    "            X_valid, y_valid = X_part, y_part\n",
    "        elif X_train is None:\n",
    "            X_train, y_train = X_part, y_part\n",
    "        else:\n",
    "            X_train = torch.cat([X_train, X_part], 0)\n",
    "            y_train = torch.cat([y_train, y_part], 0)\n",
    "    return X_train, y_train, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30] log rmse:0.11434\n",
      "[61] log rmse:0.10649\n",
      "[92] log rmse:0.10092\n",
      "[123] log rmse:0.09818\n",
      "[154] log rmse:0.09607\n",
      "[185] log rmse:0.09431\n",
      "[216] log rmse:0.09421\n",
      "[247] log rmse:0.09446\n",
      "[278] log rmse:0.09242\n",
      "[309] log rmse:0.09149\n",
      "[340] log rmse:0.09126\n",
      "[371] log rmse:0.09217\n",
      "[402] log rmse:0.09192\n",
      "[433] log rmse:0.08874\n",
      "[464] log rmse:0.08863\n",
      "[495] log rmse:0.09144\n",
      "[526] log rmse:0.08963\n",
      "[557] log rmse:0.09049\n",
      "[588] log rmse:0.09354\n",
      "[619] log rmse:0.08856\n",
      "[650] log rmse:0.08804\n",
      "[681] log rmse:0.08706\n",
      "[712] log rmse:0.08973\n",
      "[743] log rmse:0.08667\n",
      "[774] log rmse:0.08655\n",
      "[805] log rmse:0.08638\n",
      "[836] log rmse:0.08633\n",
      "[867] log rmse:0.08692\n",
      "[898] log rmse:0.09281\n",
      "[929] log rmse:0.08573\n",
      "[960] log rmse:0.08720\n",
      "[991] log rmse:0.08573\n",
      "final log rmse：0.089369\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "num_epochs = 1000\n",
    "lr = 0.5\n",
    "weight_decay = 0\n",
    "batch_size = 64\n",
    "\n",
    "def train_and_pred(train_features, test_features, train_labels, test_data,\n",
    "                   num_epochs, lr, weight_decay, batch_size):\n",
    "    net = get_net()\n",
    "    train_ls, _ = train(net, train_features, train_labels, None, None,\n",
    "                        num_epochs, lr, weight_decay, batch_size)\n",
    "    print(f'final log rmse：{float(train_ls[-1]):f}')\n",
    "    preds = net(test_features).detach().numpy()\n",
    "    test_data['SalePrice'] = pd.Series(preds.reshape(1, -1)[0])\n",
    "    submission = pd.concat([test_data['Id'], test_data['SalePrice']], axis=1)\n",
    "    submission.to_csv(os.path.join(data_root, 'submission.csv'), index=False)\n",
    "\n",
    "train_and_pred(train_features, test_features, train_labels, test_data,\n",
    "               num_epochs, lr, weight_decay, batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
